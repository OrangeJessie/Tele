{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:01:18.128006Z",
     "start_time": "2018-11-16T08:01:18.111053Z"
    }
   },
   "outputs": [],
   "source": [
    "#import dask.dataframe as dd\n",
    "#from dask.multiprocessing import get\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, mean_squared_error,mean_absolute_error, f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold,GroupKFold\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utils import *\n",
    "#from utils2 import *\n",
    "#from utils3 import *\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "#from tqdm import tqdm\n",
    "#test\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "USE_KFOLD = True\n",
    "\n",
    "data_path = './input/'\n",
    "output_path = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:01:18.855099Z",
     "start_time": "2018-11-16T08:01:18.851075Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将能转换成float的转换，不能的填充为nan\n",
    "def astype(x,t):\n",
    "    try:\n",
    "        return t(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:01:19.314834Z",
     "start_time": "2018-11-16T08:01:19.310845Z"
    }
   },
   "outputs": [],
   "source": [
    "# x为整数返回0，为小数返回1\n",
    "def have_0(x):\n",
    "    try:\n",
    "        r = x.split('.')[1][-1]\n",
    "        return 0 if r=='0' else 1\n",
    "    except:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:01:19.759646Z",
     "start_time": "2018-11-16T08:01:19.755658Z"
    }
   },
   "outputs": [],
   "source": [
    "str_dict = {'1_total_fee': 'str',\n",
    " '2_total_fee': 'str',\n",
    " '3_total_fee': 'str',\n",
    " '4_total_fee': 'str',\n",
    " 'pay_num': 'str',\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:01:20.191492Z",
     "start_time": "2018-11-16T08:01:20.188500Z"
    }
   },
   "outputs": [],
   "source": [
    "# 跟金额相关的特征\n",
    "have_0_c = ['1_total_fee','2_total_fee','3_total_fee','4_total_fee','pay_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:01:20.629351Z",
     "start_time": "2018-11-16T08:01:20.622339Z"
    }
   },
   "outputs": [],
   "source": [
    "def deal(data):\n",
    "    for c in have_0_c:\n",
    "        data['have_0_{}'.format(c)] = data[c].apply(have_0)\n",
    "        try:\n",
    "            data[c] = data[c].astype(float)\n",
    "        except:\n",
    "            pass\n",
    "    data['2_total_fee'] = data['2_total_fee'].apply(lambda x: astype(x,float))\n",
    "    data['3_total_fee'] = data['3_total_fee'].apply(lambda x: astype(x,float))\n",
    "    data['age'] = data['age'].apply(lambda x: astype(x,int))\n",
    "    data['gender'] = data['gender'].apply(lambda x: astype(x,int))\n",
    "    data.loc[data['age']==0,'age'] = np.nan\n",
    "    data.loc[data['1_total_fee'] < 0, '1_total_fee'] = np.nan\n",
    "    data.loc[data['2_total_fee'] < 0, '2_total_fee'] = np.nan\n",
    "    data.loc[data['3_total_fee'] < 0, '3_total_fee'] = np.nan\n",
    "    data.loc[data['4_total_fee'] < 0, '4_total_fee'] = np.nan\n",
    "    for c in [\n",
    "    '1_total_fee', '2_total_fee', '3_total_fee', '4_total_fee',\n",
    "    'month_traffic', 'last_month_traffic', 'local_trafffic_month',\n",
    "    'local_caller_time', 'service1_caller_time', 'service2_caller_time',\n",
    "    'many_over_bill', 'contract_type', 'contract_time', 'pay_num', ]:\n",
    "        data[c] = data[c].round(4)\n",
    "    # 添加一列，有重复的数据，该列为True，无重复数据，该列为False\n",
    "    data['is_duplicated'] =data.duplicated(subset=['1_total_fee','2_total_fee','3_total_fee', \n",
    " 'month_traffic','pay_times','last_month_traffic','service2_caller_time','age'],keep=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:01:22.444850Z",
     "start_time": "2018-11-16T08:01:21.063160Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path + 'train.csv',dtype=str_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:01:22.868717Z",
     "start_time": "2018-11-16T08:01:22.789927Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train[train['current_service'] != 999999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:01:25.435855Z",
     "start_time": "2018-11-16T08:01:23.224765Z"
    }
   },
   "outputs": [],
   "source": [
    "train = deal(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:01:27.183544Z",
     "start_time": "2018-11-16T08:01:25.743032Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(data_path + 'test.csv',dtype=str_dict)\n",
    "test = deal(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:01:34.586357Z",
     "start_time": "2018-11-16T08:01:27.492516Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_old = pd.read_csv('./input/train_old.csv',dtype=str_dict)[:]\n",
    "train_old = deal(train_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:01:34.910463Z",
     "start_time": "2018-11-16T08:01:34.901488Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_magic_feature(df, outname):\n",
    "    \"\"\"\n",
    "    It is the magic beer and niaobu, try it and enjoy!\n",
    "    \"\"\"\n",
    "    # 每一个样本total_fee 不一样的个数\n",
    "    df['fea_unum'] = df[['1_total_fee','2_total_fee','3_total_fee', '4_total_fee']].nunique(axis=1)\n",
    "    df.drop_duplicates(subset =['1_total_fee','2_total_fee','3_total_fee', '4_total_fee'],inplace=True)\n",
    "    # 保留不一样个数大于两个的\n",
    "    df = df[df.fea_unum>2]\n",
    "    # 写出所有的月份组合\n",
    "    for month1_month2 in [\n",
    "        [1,3],\n",
    "        [1,4],\n",
    "        [2,1],\n",
    "        [2,3],\n",
    "        [2,4],\n",
    "        [3,1],\n",
    "        [3,2],\n",
    "        [3,4],\n",
    "        [4,1],\n",
    "        [4,2],\n",
    "        [4,3],\n",
    "    ]:\n",
    "        month1, month2 = str(month1_month2[0]), str(month1_month2[1])\n",
    "        mstr = '_total_fee'\n",
    "        # 每一个月份组合下，两个total_fee的频数统计\n",
    "        tmp = df.groupby([month1 + mstr, month2 + mstr]).size().reset_index()\n",
    "        tmp.columns =['first','second','{}_total_fee_{}_total_fee'.format(month1,month2)]\n",
    "        # 将频数统计合并\n",
    "        if month1_month2 == [1,3]:\n",
    "            result_df = tmp\n",
    "        else:\n",
    "            result_df = result_df.merge(tmp, on = ['first','second'], how = 'outer')\n",
    "\n",
    "    tmpall = result_df\n",
    "    tmpall = tmpall[tmpall.second!=0]\n",
    "    tmpall['count'] =  tmpall.iloc[:,2:].sum(axis=1)\n",
    "    tmpall = tmpall.merge(tmpall.groupby('second',as_index=False)['count'].agg({'sum':'sum'}),on='second',how='left')\n",
    "    tmpall['rate'] = tmpall['count'] / tmpall['sum']\n",
    "    tmpall = tmpall.sort_values(['first','rate'],ascending=False)\n",
    "    tmpall =  tmpall [tmpall['count']>10]\n",
    "    tmpall = tmpall.sort_values(['first','count'],ascending=False)\n",
    "    tmp_res = tmpall.drop_duplicates('first',keep='first')\n",
    "    tmp_res[tmp_res['count']>10].to_csv(outname, columns = ['first','count'],index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:01:35.566707Z",
     "start_time": "2018-11-16T08:01:35.230608Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train.append(test).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:02:19.711699Z",
     "start_time": "2018-11-16T08:01:35.918767Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "get_magic_feature(train, 'Magic_Feature_Exclude_Old.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:02:20.332068Z",
     "start_time": "2018-11-16T08:02:20.056777Z"
    }
   },
   "outputs": [],
   "source": [
    "train.drop_duplicates(subset = ['1_total_fee','2_total_fee','3_total_fee',\n",
    " 'month_traffic','pay_times','last_month_traffic','service2_caller_time','age'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T02:33:46.291258Z",
     "start_time": "2018-11-16T02:32:59.197152Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:04:03.422219Z",
     "start_time": "2018-11-16T08:02:20.664154Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "train = train.append(train_old).reset_index(drop = True)\n",
    "train.drop_duplicates(subset = ['1_total_fee','2_total_fee','3_total_fee',\n",
    " 'month_traffic','pay_times','last_month_traffic','service2_caller_time','age'],inplace=True)\n",
    "get_magic_feature(train, 'Magic_Feature_Include_Old.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T08:06:00.011561Z",
     "start_time": "2018-11-16T08:04:04.152266Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "train.drop_duplicates(subset = ['1_total_fee','2_total_fee','3_total_fee',\n",
    " 'month_traffic','pay_times','last_month_traffic','service2_caller_time','age'],inplace=True)\n",
    "get_magic_feature(train, 'Magic_Feature_Include_Old.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "214px",
    "left": "948px",
    "right": "20px",
    "top": "159px",
    "width": "402px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
